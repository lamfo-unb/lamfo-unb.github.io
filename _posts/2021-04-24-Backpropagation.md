---

layout: post
title: "Backpropagation e algoritmos de otimização por gradiente descendente"
lang: pt
header-img: img/manipulacao_data.table/img_data.table.png
date: 2021-04-24 23:59:07
tags: [Backpropagation, Machine Learning, Statistics]
author: Jairo Alves, Vinícius Watanabe
comments: true
---

# Backpropagation e algoritmos de otimização por gradiente descendente

## Vídeo 1 - Parte teórica
Um dos principais pilares de Machine Learning é o conceito de Backpropagation. Além de ter aberto uma gama de possibilidades para os cientistas de dados e cientistas da programação, ainda hoje é um conhecimento valiosíssimo para aqueles que se interessam sobre a área. Entretanto, para entender com plenitude a ideia da propagação reversa, é necessário entender o que vem por trás desse conceito. Por esse motivo, em primeiro lugar, apresentamos o conceito de Neural Networks (que é importante não só para o Backpropagation, mas para quase todos os assuntos em Machine Learning) e o conceito de Gradient Descent. Essa primeira introdução pode ser vista, de forma muito didática, pela apresentação de Jairo Alves feita para a oficina do LAMFO no dia 24 de abril de 2021.

Este vídeo é a primeira parte realizado pelo Pesquisador Jairo Alves. Ela apresenta a parte teórica de Backpropagation, suas características, teoria em torno e exercícios, mas antes também faz uma revisão dos conceitos de Redes Neurais, conteúdo indispensável para quem quer compreender sobre o tema.

<iframe width="560" height="315" src="https://www.youtube.com/embed/Oe3NOIjK0zE" title="Parte Teórica" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## Vídeo 2 - Parte Prática I
Além do que foi apresentado na Parte I, para aqueles que querem se aprofundar nos estudos, é necessário entender quais são as estratégias de otimização. Conhecer quais as ideias e postulados que estão por trás da otimização, e quais são os modelos usados. Uma ideia geral da evolução da história do Gradient Descent permite que o cientista saiba qual modelo usar, quando usar, e quais suas limitações. O programador realmente eficiente será aquele que, além de conhecer o problema que enfrenta, sabe qual pode ser o melhor caminho para resolver o problema. O primeiro vídeo realizado pelo Vinícius Watanabe passa por essa evolução na história do Gradient Descent, familiarizando o interessado com os modelos mais usados para otimização.


<iframe width="560" height="315" src="https://www.youtube.com/embed/Cd4S_EhCSos" title="Parte Prática I" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
